{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Chest X-rays with Cross-Modal Data Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to use the *cross-modal data programming* technique described in Dunnmon and Ratner, et al. (2019) to build a Convolutional Neural Network (CNN) model with no hand-labeled data that performs similarly to a CNN supervised using several thousand data points labeled by radiologists.  We begin by setting up our environment, importing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "# Setting path to Snorkel MeTaL\n",
    "sys.path.append('../../metal')\n",
    "# Making sure CUDA devices are visible!\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "# Importing pandas for data processing\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set up the data dictionary and load data that we've already split for you into an (approximately) 80% train split, 10% development split, and 10% test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2630 train examples: 63.8% Abnormal\n",
      "376 dev examples: 63.0% Abnormal\n",
      "378 test examples: 61.6% Abnormal\n"
     ]
    }
   ],
   "source": [
    "# Setting up data dictionary and defining data splits\n",
    "data = {}\n",
    "splits = ['train','dev','test']\n",
    "\n",
    "for split in splits:\n",
    "    data[split] = pd.read_csv(f'data/{split}_entries.csv')[['label','xray_paths','text']]\n",
    "    perc_pos = sum(data[split]['label'])/len(data[split])\n",
    "    print(f'{len(data[split])} {split} examples: {100*perc_pos:0.1f}% Abnormal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see an example of a single data point below -- note that the raw label convention is 1 for abnormal, 0 for abnormal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW TEXT:\n",
      " \n",
      " COMPARISON: Chest x-XXXX XXXX INDICATION: XXXX in bathtub FINDINGS: The lungs and pleural spaces show no acute abnormality. Hyperexpanded lungs. Calcified right upper lobe granuloma, unchanged. Heart size and pulmonary vascularity within normal limits. No displaced rib fractures. IMPRESSION: 1. Hyperexpansion without acute pulmonary abnormality. \n",
      "\n",
      "IMAGE PATHS: \n",
      " \n",
      " ./data/openi/xrays/CXR2824_IM-1245-13001.png \n",
      "\n",
      "LABEL: 1\n"
     ]
    }
   ],
   "source": [
    "sample = data['train'].iloc[0]\n",
    "print('RAW TEXT:\\n \\n',sample['text'],'\\n')\n",
    "print('IMAGE PATHS: \\n \\n', sample['xray_paths'],'\\n')\n",
    "print('LABEL:', sample['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define our *labeling functions*: simple, heuristic functions written by a domain expert (e.g., a radiologist) that correctly label a report as normal or abnormal with probability better than random chance.  Note that we use our labeled *development set* to ensure that we do not include any poorly performing heuristics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy\n",
    "\n",
    "ABSTAIN = 0\n",
    "FALSE = 2 # normal\n",
    "TRUE = 1 # abnormal\n",
    "\n",
    "\n",
    "def get_text(c, name=None):\n",
    "    if name is None:\n",
    "        text = \" \".join([_.text for _ in c[0].context.document.sentences])\n",
    "    else:\n",
    "        text = \" \".join(\n",
    "            [_.text for _ in c[0].context.document.sentences if _.name == name]\n",
    "        )\n",
    "    return text\n",
    "\n",
    "\n",
    "def LF_report_is_short(c):\n",
    "    text = get_text(c)\n",
    "    return FALSE if len(text) < 280 else ABSTAIN\n",
    "\n",
    "\n",
    "negative_inflection_words = [\"but\", \"however\", \"otherwise\"]\n",
    "\n",
    "\n",
    "def LF_negative_inflection_words_in_report(c):\n",
    "    text = get_text(c)\n",
    "    return (\n",
    "        TRUE\n",
    "        if any(word in text.lower() for word in negative_inflection_words)\n",
    "        else ABSTAIN\n",
    "    )\n",
    "\n",
    "\n",
    "def LF_is_seen_or_noted_in_report(c):\n",
    "    text = get_text(c)\n",
    "    return (\n",
    "        TRUE if any(word in text.lower() for word in [\"is seen\", \"noted\"]) else ABSTAIN\n",
    "    )\n",
    "\n",
    "def LF_disease_in_report(c):\n",
    "    text = get_text(c)\n",
    "    return TRUE if \"disease\" in text.lower() else ABSTAIN\n",
    "\n",
    "\n",
    "def LF_recommend_in_report(c):\n",
    "    text = get_text(c)\n",
    "    return TRUE if \"recommend\" in text.lower() else ABSTAIN\n",
    "\n",
    "\n",
    "def LF_mm_in_report(c):\n",
    "    text = get_text(c)\n",
    "    return TRUE if any(word in text.lower() for word in [\"mm\", \"cm\"]) else ABSTAIN\n",
    "\n",
    "\n",
    "abnormal_mesh_terms = [\n",
    "    \"opacity\",\n",
    "    \"cardiomegaly\",\n",
    "    \"calcinosis\",\n",
    "    \"hypoinflation\",\n",
    "    \"calcified granuloma\",\n",
    "    \"thoracic vertebrae\",\n",
    "    \"degenerative\",\n",
    "    \"hyperdistention\",\n",
    "    \"catheters\",\n",
    "    \"granulomatous\",\n",
    "    \"nodule\",\n",
    "    \"fracture\" \"surgical\",\n",
    "    \"instruments\",\n",
    "    \"emphysema\",\n",
    "]\n",
    "\n",
    "\n",
    "def LF_abnormal_mesh_terms_in_report(c):\n",
    "    text = get_text(c)\n",
    "    if any(mesh in text.lower() for mesh in abnormal_mesh_terms):\n",
    "        return TRUE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "\n",
    "words_indicating_normalcy = [\"clear\", \"no\", \"normal\", \"unremarkable\", \"free\", \"midline\"]\n",
    "\n",
    "def LF_consistency_in_report(c):\n",
    "    \"\"\"\n",
    "    The words 'clear', 'no', 'normal', 'free', 'midline' in\n",
    "    findings section of the report\n",
    "    \"\"\"\n",
    "\n",
    "    #     report = c.report_text.text\n",
    "    #     findings = report[report.find('FINDINGS:'):]\n",
    "    #     findings = findings[:findings.find('IMPRESSION:')]\n",
    "    findings = get_text(c, name=\"FINDINGS\")\n",
    "    sents = findings.split(\".\")\n",
    "\n",
    "    num_sents_without_normal = 0\n",
    "    for sent in sents:\n",
    "        sent = sent.lower()\n",
    "        if not any(word in sent for word in words_indicating_normalcy):\n",
    "            num_sents_without_normal += 1\n",
    "        elif \"not\" in sent:\n",
    "            num_sents_without_normal += 1\n",
    "    return FALSE if num_sents_without_normal < 2 else TRUE\n",
    "\n",
    "\n",
    "categories = [\n",
    "    \"normal\",\n",
    "    \"opacity\",\n",
    "    \"cardiomegaly\",\n",
    "    \"calcinosis\",\n",
    "    \"lung/hypoinflation\",\n",
    "    \"calcified granuloma\",\n",
    "    \"thoracic vertebrae/degenerative\",\n",
    "    \"lung/hyperdistention\",\n",
    "    \"spine/degenerative\",\n",
    "    \"catheters, indwelling\",\n",
    "    \"granulomatous disease\",\n",
    "    \"nodule\",\n",
    "    \"surgical instruments\",\n",
    "    \"scoliosis\",\n",
    "    \"osteophyte\",\n",
    "    \"spondylosis\",\n",
    "    \"fractures, bone\",\n",
    "]\n",
    "\n",
    "\n",
    "def LF_normal(report):\n",
    "    r = re.compile(\"No acute cardiopulmonary abnormality\", re.IGNORECASE)\n",
    "    text = get_text(report)\n",
    "    for s in text.split(\".\"):\n",
    "        if r.search(s):\n",
    "            return FALSE\n",
    "    return ABSTAIN\n",
    "\n",
    "reg_equivocation = re.compile(\n",
    "    (\n",
    "        r\"unlikely|likely|suggests|questionable|concerning|possibly|potentially|\"\n",
    "        r\"could represent|may represent|may relate|cannot exclude|can't exclude|may be\"\n",
    "    ),\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "\n",
    "def LF_positive_MeshTerm(report):\n",
    "    text = get_text(report)\n",
    "    for idx in range(1, len(categories)):\n",
    "        reg_pos = re.compile(categories[idx], re.IGNORECASE)\n",
    "        reg_neg = re.compile(\n",
    "            r\"(No|without|resolution)\\\\s([a-zA-Z0-9\\-,_]*\\\\s){0,10}\" + categories[idx],\n",
    "            re.IGNORECASE,\n",
    "        )\n",
    "        for s in text.split(\".\"):\n",
    "            if (\n",
    "                reg_pos.search(s)\n",
    "                and (not reg_neg.search(s))\n",
    "                and (not reg_equivocation.search(s))\n",
    "            ):\n",
    "                return TRUE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def LF_fracture(report):\n",
    "    text = get_text(report)\n",
    "    reg_pos = re.compile(\"fracture\", re.IGNORECASE)\n",
    "    reg_neg = re.compile(\n",
    "        r\"(No|without|resolution)\\\\s([a-zA-Z0-9\\-,_]*\\\\s){0,10}fracture\", re.IGNORECASE\n",
    "    )\n",
    "    for s in text.split(\".\"):\n",
    "        if (\n",
    "            reg_pos.search(s)\n",
    "            and (not reg_neg.search(s))\n",
    "            and (not reg_equivocation.search(s))\n",
    "        ):\n",
    "            return TRUE\n",
    "    return ABSTAIN\n",
    "\n",
    "def LF_calcinosis(report):\n",
    "    text = get_text(report)\n",
    "    reg_01 = re.compile(\"calc\", re.IGNORECASE)\n",
    "    reg_02 = re.compile(\"arter|aorta|muscle|tissue\", re.IGNORECASE)\n",
    "    for s in text.split(\".\"):\n",
    "        if reg_01.search(s) and reg_02.search(s):\n",
    "            return TRUE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def LF_degen_spine(report):\n",
    "    text = get_text(report)\n",
    "    reg_01 = re.compile(\"degen\", re.IGNORECASE)\n",
    "    reg_02 = re.compile(\"spine\", re.IGNORECASE)\n",
    "    for s in text.split(\".\"):\n",
    "        if reg_01.search(s) and reg_02.search(s):\n",
    "            return TRUE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def LF_lung_hypoinflation(report):\n",
    "    text = get_text(report)\n",
    "    # reg_01 = re.compile('lung|pulmonary',re.IGNORECASE)\n",
    "    reg_01 = re.compile(\n",
    "        (\n",
    "            r\"hypoinflation|collapse|(low|decrease|diminish)\\\\s\"\n",
    "            r\"([a-zA-Z0-9\\-,_]*\\\\s){0,4}volume\"\n",
    "        ),\n",
    "        re.IGNORECASE,\n",
    "    )\n",
    "    for s in text.split(\".\"):\n",
    "        if reg_01.search(s):\n",
    "            return TRUE\n",
    "    return ABSTAIN\n",
    "\n",
    "def LF_lung_hyperdistention(report):\n",
    "    text = get_text(report)\n",
    "    # reg_01 = re.compile('lung|pulmonary',re.IGNORECASE)\n",
    "    reg_01 = re.compile(\"increased volume|hyperexpan|inflated\", re.IGNORECASE)\n",
    "    for s in text.split(\".\"):\n",
    "        if reg_01.search(s):\n",
    "            return TRUE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def LF_catheters(report):\n",
    "    text = get_text(report)\n",
    "    reg_01 = re.compile(\" line|catheter|PICC\", re.IGNORECASE)\n",
    "    for s in text.split(\".\"):\n",
    "        if reg_01.search(s):\n",
    "            return TRUE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def LF_surgical(report):\n",
    "    text = get_text(report)\n",
    "    reg_01 = re.compile(\"clip\", re.IGNORECASE)\n",
    "    for s in text.split(\".\"):\n",
    "        if reg_01.search(s):\n",
    "            return TRUE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def LF_granuloma(report):\n",
    "    text = get_text(report)\n",
    "    reg_01 = re.compile(\"granuloma\", re.IGNORECASE)\n",
    "    for s in text.split(\".\"):\n",
    "        if reg_01.search(s):\n",
    "            return TRUE\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from metal.analysis import single_lf_summary, confusion_matrix\n",
    "\n",
    "# Testing single LF\n",
    "lf_test = lf_impression_section_positive\n",
    "\n",
    "# Computing labels\n",
    "Y_lf = np.array([lf_test(doc) for doc in dev_docs])\n",
    "single_lf_summary(Y_lf, Y=Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix\n",
    "conf = confusion_matrix(Y_dev, Y_lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFs = [\n",
    "    LF_report_is_short,\n",
    "    LF_consistency_in_report,\n",
    "    LF_negative_inflection_words_in_report,\n",
    "    LF_is_seen_or_noted_in_report,\n",
    "    LF_disease_in_report,\n",
    "    LF_abnormal_mesh_terms_in_report,\n",
    "    LF_recommend_in_report,\n",
    "    LF_mm_in_report,\n",
    "    LF_normal,\n",
    "    LF_positive_MeshTerm,\n",
    "    LF_fracture,\n",
    "    LF_calcinosis,\n",
    "    LF_degen_spine,\n",
    "    LF_lung_hypoinflation,\n",
    "    LF_lung_hyperdistention,\n",
    "    LF_catheters,\n",
    "    LF_surgical,\n",
    "    LF_granuloma,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "from eeg_utils import evaluate_lf_on_docs, create_label_matrix\n",
    "import pickle\n",
    "\n",
    "# Resetting LFs\n",
    "clobber_lfs = True\n",
    "Ls_file = 'Ls_0p3.pkl'\n",
    "Ys_file = 'Ys_0p3.pkl'\n",
    "\n",
    "# Get lf names\n",
    "lf_names = [lf.__name__ for lf in lfs]\n",
    "\n",
    "# Loading Ls if they exist\n",
    "\n",
    "Ls = []\n",
    "Ys = []\n",
    "if clobber_lfs or (not os.path.exists(Ls_file)):\n",
    "    print('Computing label matrices...')\n",
    "    for i, docs in enumerate([train_docs, dev_docs, test_docs]):\n",
    "        Ls.append(create_label_matrix(lfs,docs))  \n",
    "    with open(Ls_file,'wb') as af:\n",
    "        pickle.dump(Ls, af)\n",
    "    \n",
    "    print('Creating label vectors...')\n",
    "    Ys = [[],Y_dev, Y_test]\n",
    "    with open(Ys_file,'wb') as af:\n",
    "        pickle.dump(Ls, af)\n",
    "else:\n",
    "    print('Loading pre-computed label matrices...')\n",
    "    with open(Ls_file,'rb') as af:\n",
    "        Ls=pickle.load(af) \n",
    "        \n",
    "\n",
    "# Create label matrices\n",
    "#Ls = []\n",
    "#for i, docs in enumerate([train_docs, dev_docs, test_docs]):\n",
    "#    Ls.append(create_label_matrix(lfs,docs)) \n",
    "    \n",
    "# Create Ys\n",
    "Ys = [[], Y_dev, Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.analysis import lf_summary\n",
    "\n",
    "# Analyzing LF stats\n",
    "df_lf = lf_summary(Ls[1], Y=Y_dev, lf_names=lf_names)\n",
    "df_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  metal.contrib.visualization.analysis import view_conflicts\n",
    "\n",
    "# Viewing conflicts\n",
    "view_conflicts(Ls[1], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.label_model import LabelModel\n",
    "from metal.utils import LogWriter\n",
    "from metal.tuners import RandomSearchTuner\n",
    "\n",
    "# Creating metal label model\n",
    "#label_model = LabelModel(k=2, seed=123)\n",
    "\n",
    "# Creating search space\n",
    "search_space = {\n",
    "        'l2': {'range': [0.0001, 0.1], 'scale':'log'},           # linear range\n",
    "        'lr': {'range': [0.0001, 0.01], 'scale': 'log'},  # log range\n",
    "        }\n",
    "\n",
    "searcher = RandomSearchTuner(LabelModel, log_dir='./run_logs',\n",
    "               log_writer_class=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Training label model\n",
    "label_model = searcher.search(search_space, (Ls[1],Ys[1]), \\\n",
    "        train_args=[Ls[0]], init_args=[],\n",
    "        init_kwargs={'k':2, 'seed':123}, train_kwargs={'n_epochs':100},\n",
    "        max_search=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving best model\n",
    "searcher._save_best_model(label_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting scores\n",
    "scores = label_model.score((Ls[1], Ys[1]), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.label_model.baselines import MajorityLabelVoter\n",
    "\n",
    "# Checking if we beat majority vote\n",
    "mv = MajorityLabelVoter(seed=123)\n",
    "scores = mv.score((Ls[1], Ys[1]), metric=['accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting probabilistic training labels\n",
    "# Y_train_ps stands for \"Y[labels]_train[split]_p[redicted]s[oft]\"\n",
    "Y_train_ps = label_model.predict_proba(Ls[0])\n",
    "Y_dev_ps = label_model.predict_proba(Ls[1])\n",
    "Y_test_ps = label_model.predict_proba(Ls[2])\n",
    "Y_ps = [Y_train_ps, Y_dev_ps, Y_test_ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running some analysis \n",
    "from metal.contrib.visualization.analysis import plot_predictions_histogram\n",
    "Y_dev_p = label_model.predict(Ls[1])\n",
    "plot_predictions_histogram(Y_dev_p, Ys[1], title=\"Label Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  metal.contrib.visualization.analysis  import plot_probabilities_histogram\n",
    "\n",
    "# Looking at probability histogram for training labels\n",
    "plot_probabilities_histogram(Y_dev_ps[:,0], title=\"Probablistic Label Distribution\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
